{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d2693f3-c36a-426d-ab5b-543f3bc393e3",
   "metadata": {},
   "source": [
    "# カタカナの画像認識モデル\n",
    "手書きカタカナ「アイウエオカキクケコサシスセソ」の15文字を高い精度で識別できるモデルを構築する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf8310-d327-46d1-bfbf-661de0a0efe8",
   "metadata": {},
   "source": [
    "## MLFlow準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b794c8-1d90-4bcb-8917-888371b22417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "# ローカルDB方式の場合に必要。今回はローカルGUI方式のため不要\n",
    "# import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb360c8c-6287-4bca-a256-10f567ceca34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./config.ini']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLFlowの設定ファイル読み込み\n",
    "cfg = configparser.ConfigParser()\n",
    "cfg.read('./config.ini', encoding='utf-8')\n",
    "# 各種パスを指定\n",
    "# DB_PATH = cfg['Path']['db_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d1f435-de75-4c4d-920c-0383a1bf0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% エクスペリメントの作成\n",
    "# Artifactストレージの場所を指定\n",
    "ARTIFACT_LOCATION = cfg['Path']['artifact_location']\n",
    "# Experimentの生成\n",
    "EXPERIMENT_NAME = 'cnn_tuning'\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment is None:  # 当該Experiment存在しないとき、新たに作成\n",
    "    experiment_id = mlflow.create_experiment(\n",
    "                            name=EXPERIMENT_NAME,\n",
    "                            artifact_location=ARTIFACT_LOCATION)\n",
    "else: # 当該Experiment存在するとき、IDを取得\n",
    "    experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db0e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ce10f3",
   "metadata": {},
   "source": [
    "## データ準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcedace",
   "metadata": {},
   "source": [
    "### 訓練データ&検証データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23808a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"../1_data/train_data.npy\")\n",
    "train_label = np.load(\"../1_data/train_label.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68c3e0a5-5f01-4c0a-b2ab-f338cf74e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化\n",
    "train_data = (train_data - train_data.min()) / train_data.max()\n",
    "train_data = train_data.astype('float32')\n",
    "# print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b387f8-ce65-40f8-8c60-f6637dbff14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape= (3000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 配列形式変更\n",
    "train_data = train_data.reshape(-1, 28*28)\n",
    "print(\"train_data.shape=\", train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "592257fb-4e47-4e27-9e2c-49e87a822c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2100, 784) (900, 784)\n"
     ]
    }
   ],
   "source": [
    "train, valid, y_train, y_valid = train_test_split(train_data, train_label, \n",
    "                                                    test_size=0.3, random_state=1234,\n",
    "                                                    shuffle=True\n",
    "                                                   )\n",
    "\n",
    "print(train.shape, valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d688109d-725e-4e91-8d76-948fe460e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配列形式変更\n",
    "train = train.reshape(-1, 1, 28, 28)\n",
    "valid = valid.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9077ac40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習用データの形状：(2100, 1, 28, 28)\n",
      "学習用ラベルの形状：(2100, 15)\n",
      "検証用データの形状：(900, 1, 28, 28)\n",
      "検証用ラベルの形状：(900, 15)\n"
     ]
    }
   ],
   "source": [
    "print(f'学習用データの形状：{train.shape}')\n",
    "print(f'学習用ラベルの形状：{y_train.shape}')\n",
    "print(f'検証用データの形状：{valid.shape}')\n",
    "print(f'検証用ラベルの形状：{y_valid.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d76640",
   "metadata": {},
   "source": [
    "## モデル構築・学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40df5936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 23:01:27.702171: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-08 23:01:27.950337: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-08 23:01:27.950410: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-08 23:01:27.985775: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-08 23:01:29.083744: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-08 23:01:29.084277: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-08 23:01:29.084310: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "batchnorm=False\n",
    "if batchnorm:\n",
    "    from common.deep_convnet import DeepConvNetBatchNorm as DeepConvNet\n",
    "else:\n",
    "    from common.deep_convnet import DeepConvNet\n",
    "\n",
    "from common.trainer_onlineaugmented import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a955b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled = 200 # 高速化のため\n",
    "# train = train[:sampled]\n",
    "# y_train = y_train[:sampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c02262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データをセット\n",
      "trainのshape：(2100, 1, 28, 28)\n",
      "y_trainのshape：(2100, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"訓練データをセット\")\n",
    "print(f'trainのshape：{train.shape}')\n",
    "print(f'y_trainのshape：{y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d970b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数の固定\n",
    "_random_seed = 42\n",
    "np.random.seed(_random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88fc08b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ネットワーク生成完了\n"
     ]
    }
   ],
   "source": [
    "# ネットワーク生成（モデル構築）\n",
    "network = DeepConvNet()  \n",
    "print(\"ネットワーク生成完了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7106c37b-1ddb-4a13-bf1a-2ad79a110cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_param = {\n",
    "    'zoom_range': [0.7, 1.3],\n",
    "    'rotation_range': 40,\n",
    "    'vertical_flip': False,\n",
    "    'horizontal_flip': False,\n",
    "    'height_shift_range': 0.1,\n",
    "    'width_shift_range': 0.1,\n",
    "    'shear_range': 40,\n",
    "    # 'channel_shift_range': 127\n",
    "}\n",
    "add_image_num = 420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cf3ad14-9486-4787-8163-91b88a436df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _epochs=4\n",
    "# _mini_batch_size=420\n",
    "# _optimizer='RMSprop'\n",
    "# _optimizer_param={'lr':0.01, 'decay_rate':0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34f3c048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainerクラスのインスタンスが無事生成されました\n",
      "optimizer:<common.optimizer.RMSprop object at 0x7f4fdc2e5120>\n",
      "総iter数：400 = エポック数：80, ミニバッチ数：5.0\n",
      "進捗：0.0%, 訓練データの誤差：12.4\n",
      "==epoch:1, train_acc:0.066, test_acc:0.0667==\n",
      "進捗：0.2%, 訓練データの誤差：2.7\n",
      "進捗：0.5%, 訓練データの誤差：2.71\n",
      "進捗：0.8%, 訓練データの誤差：2.71\n",
      "進捗：1.0%, 訓練データの誤差：2.71\n",
      "進捗：1.2%, 訓練データの誤差：2.71\n",
      "==epoch:2, train_acc:0.068, test_acc:0.0667==\n",
      "進捗：1.5%, 訓練データの誤差：2.71\n",
      "進捗：1.8%, 訓練データの誤差：2.71\n",
      "進捗：2.0%, 訓練データの誤差：2.71\n",
      "進捗：2.2%, 訓練データの誤差：2.71\n",
      "進捗：2.5%, 訓練データの誤差：2.71\n",
      "==epoch:3, train_acc:0.079, test_acc:0.0544==\n",
      "進捗：2.8%, 訓練データの誤差：2.71\n",
      "進捗：3.0%, 訓練データの誤差：2.71\n",
      "進捗：3.2%, 訓練データの誤差：2.71\n",
      "進捗：3.5%, 訓練データの誤差：2.71\n",
      "進捗：3.8%, 訓練データの誤差：2.7\n",
      "==epoch:4, train_acc:0.077, test_acc:0.0589==\n",
      "進捗：4.0%, 訓練データの誤差：2.71\n",
      "進捗：4.2%, 訓練データの誤差：2.71\n",
      "進捗：4.5%, 訓練データの誤差：2.71\n",
      "進捗：4.8%, 訓練データの誤差：2.71\n",
      "進捗：5.0%, 訓練データの誤差：2.71\n",
      "==epoch:5, train_acc:0.097, test_acc:0.0844==\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 17\u001b[0m\n\u001b[1;32m      6\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(network, train, y_train, valid, y_valid,\n\u001b[1;32m      7\u001b[0m                   aug_param, add_image_num, \n\u001b[1;32m      8\u001b[0m                   epochs\u001b[38;5;241m=\u001b[39m_epochs, mini_batch_size\u001b[38;5;241m=\u001b[39m_mini_batch_size, \n\u001b[1;32m      9\u001b[0m                   optimizer\u001b[38;5;241m=\u001b[39m_optimizer, optimizer_param\u001b[38;5;241m=\u001b[39m_optimizer_param,\n\u001b[1;32m     10\u001b[0m                   evaluate_sample_num_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# trainer = Trainer(network, train, y_train, valid, y_valid,\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#                   epochs=20, mini_batch_size=100,\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#                   optimizer='Adam', optimizer_param={'lr':0.001},\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#                   evaluate_sample_num_per_epoch=1000)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/work/ktkn_ocr/2_notebook/common/trainer_onlineaugmented.py:123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# 最後のエポックまでの総iter回tra_step()を実行する\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter):\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;66;03m# print(f'train{i}回目（全{self.max_iter}回）')\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39maccuracy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_test)\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/work/ktkn_ocr/2_notebook/common/trainer_onlineaugmented.py:66\u001b[0m, in \u001b[0;36mTrainer.train_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m x_batch, t_batch \u001b[38;5;241m=\u001b[39m data_augmentation(x_batch, t_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maug_params, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_image_num)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# print(\"x_batch.shape=\", x_batch.shape)\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# print(\"t_batch.shape=\", t_batch.shape)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# 勾配計算\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# print(\"勾配計算完了\")\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# 更新\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mparams, grads)\n",
      "File \u001b[0;32m~/work/ktkn_ocr/2_notebook/common/deep_convnet.py:314\u001b[0m, in \u001b[0;36mDeepConvNet.gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    312\u001b[0m tmp_layers\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m tmp_layers:\n\u001b[0;32m--> 314\u001b[0m     dout \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# 設定\u001b[39;00m\n\u001b[1;32m    317\u001b[0m grads \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/work/ktkn_ocr/2_notebook/common/layers.py:255\u001b[0m, in \u001b[0;36mConvolution.backward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdW \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdW\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(FN, C, FH, FW)\n\u001b[1;32m    254\u001b[0m dcol \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(dout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_W\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m--> 255\u001b[0m dx \u001b[38;5;241m=\u001b[39m \u001b[43mcol2im\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx\n",
      "File \u001b[0;32m~/work/ktkn_ocr/2_notebook/common/util.py:97\u001b[0m, in \u001b[0;36mcol2im\u001b[0;34m(col, input_shape, filter_h, filter_w, stride, pad)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(filter_w):\n\u001b[1;32m     96\u001b[0m         x_max \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m stride\u001b[38;5;241m*\u001b[39mout_w\n\u001b[0;32m---> 97\u001b[0m         img[:, :, y:y_max:stride, x:x_max:stride] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m col[:, :, y, x, :, :]\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img[:, :, pad:H \u001b[38;5;241m+\u001b[39m pad, pad:W \u001b[38;5;241m+\u001b[39m pad]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_epochs=80\n",
    "_mini_batch_size=420\n",
    "_optimizer='RMSprop'\n",
    "_optimizer_param={'lr':0.01, 'decay_rate':0.9}\n",
    "# 学習\n",
    "trainer = Trainer(network, train, y_train, valid, y_valid,\n",
    "                  aug_param, add_image_num, \n",
    "                  epochs=_epochs, mini_batch_size=_mini_batch_size, \n",
    "                  optimizer=_optimizer, optimizer_param=_optimizer_param,\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "\n",
    "# trainer = Trainer(network, train, y_train, valid, y_valid,\n",
    "#                   epochs=20, mini_batch_size=100,\n",
    "#                   optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "#                   evaluate_sample_num_per_epoch=1000)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63735b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = trainer.train_acc_list\n",
    "train_loss = trainer.train_loss_list\n",
    "valid_acc = trainer.test_acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39512d48-d1af-4f12-8874-411f13d157c6",
   "metadata": {},
   "source": [
    "### MLFlowに記録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da21f41-d958-433c-b1e6-9d44cc8311cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "\n",
    "# 管理IDを発行（コードの実行に対して）\n",
    "with mlflow.start_run(experiment_id=experiment_id):\n",
    "\n",
    "    # ハイパーパラメータ, 評価指標, 学習済みモデルをMLflowへ保存\n",
    "    ## データ拡張のパラメータ\n",
    "    mlflow.log_param(\"aug_param\", aug_param)\n",
    "    mlflow.log_param(\"add_image_num\", add_image_num)\n",
    "    ## 学習のパラメータ\n",
    "    mlflow.log_param(\"epochs\", _epochs)\n",
    "    mlflow.log_param(\"mini_batch_size\", _mini_batch_size)\n",
    "    mlflow.log_param(\"optimizer\", _optimizer)\n",
    "    mlflow.log_param(\"optimizer_param\", _optimizer_param)\n",
    "    mlflow.log_param(\"batchnorm\", batchnorm)\n",
    "    mlflow.log_param(\"random_seed\", _random_seed)\n",
    "    ## 評価指標\n",
    "    mlflow.log_metric(\"train_acc\", train_acc[-1])\n",
    "    mlflow.log_metric(\"train_loss\", train_loss[-1])\n",
    "    mlflow.log_metric(\"valid_acc\", valid_acc[-1])\n",
    "    # mlflow.log_param(\"\", )\n",
    "\n",
    "    \n",
    "    # mlflow.log_param(\"filter_num\", filter_num)\n",
    "    # mlflow.log_param(\"filter_size\", filter_size)\n",
    "    # mlflow.log_param(\"weight_init_std\", weight_init_std)\n",
    "\n",
    "    # mlflow.log_model(tnet, \"model\")\n",
    "\n",
    "# mlflowを終了\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3689c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_acc))\n",
    "print(len(train_loss))\n",
    "print(len(valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lossとaccuracyのグラフ化\n",
    "df_log = pd.DataFrame({\"train_loss\":train_loss,\n",
    "             # \"valid_loss\":valid_loss,\n",
    "             \"train_acc\":train_acc,\n",
    "             \"valid_acc\":valid_acc})\n",
    "\n",
    "df_log.plot(style=['r-', 'b-', 'b--'])\n",
    "plt.ylim([0,3])\n",
    "plt.ylabel(\"Accuracy or loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef4865",
   "metadata": {},
   "source": [
    "### 学習済みモデルの出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d1c2ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"katakana_model.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(tnet, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea5637e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Network Parameters!\n"
     ]
    }
   ],
   "source": [
    "network.save_params(\"katakana_model.pickle\")\n",
    "print(\"Saved Network Parameters!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3f94ca-a494-47f4-b4de-1e6113a1d23d",
   "metadata": {},
   "source": [
    "## 誤答を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed223045-9ae3-4079-bac2-8e69e874b261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<common.deep_convnet.DeepConvNet object at 0x7f8024c1f190>\n",
      "(900, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(network)\n",
    "print(valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5baa6963-0bcc-415c-a321-40bf206758b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-10.01048513,  -6.57092927, -22.31079914, ...,   6.48576623,\n",
       "        -10.46153824, -15.10864127],\n",
       "       [-16.41993826, -21.49478571,   6.00406515, ..., -17.78268256,\n",
       "        -12.06279736, -10.73445212],\n",
       "       [-30.01175184, -25.78453843, -20.28555109, ..., -15.62475733,\n",
       "        -20.96645594,  -9.80670294],\n",
       "       ...,\n",
       "       [ -4.67686146,   5.29008032, -12.27082244, ...,  -3.75721018,\n",
       "        -10.99703748,  -9.40572712],\n",
       "       [ -4.14520855,  -7.8437439 ,  -4.37235523, ...,  -8.16081732,\n",
       "         -5.26712889,  -5.82723493],\n",
       "       [-15.74929326, -13.77952663,  -8.49608855, ...,  -8.92146507,\n",
       "        -13.15932414,  -5.90590662]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.predict(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa436e-a46f-4f2d-86b0-931ce96b0467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
